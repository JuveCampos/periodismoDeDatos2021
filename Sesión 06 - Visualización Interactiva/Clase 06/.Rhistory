# Heatmaps en R ----
library(tidyverse)
library(plotly)
coches = readxl::read_xlsx("01_Datos/coches.xlsx") %>%
mutate(text = str_c("<b>Entidad:</b> ", ent, "<br>",
"<b>Año: </b>", year, "<br>",
"<b>Valor: </b>", prettyNum(round(valor, 2), big.mark = ",")
))
# Version 1
plt_1 <- coches %>%
filter(ent != "Nacional") %>%
ggplot(aes(x = year,
y = valor,
group = ent,
text = text)) +
geom_line()
# Convertimos a interactiva
ggplotly(plt_1, tooltip = "text")
# Version 2
plt_2 = coches %>%
filter(ent != "Nacional") %>%
ggplot(aes(x = year,
y = valor,
group = ent,
text = text)) +
geom_line() +
facet_wrap(~ent,
ncol = 4)
# Convertimos a interactiva
ggplotly(plt_2, tooltip = "text")
# Versión 3
density(coches$valor)
# Modificacion de los datos: para que la grafica vaya de antes a despues
coches <- coches %>%
mutate(year_factor = factor(year,
levels = rev(unique(coches$year))))
# Grafica ----
plot = coches %>%
filter(ent != "Nacional") %>%
ggplot(aes(x = ent,
y = year_factor,
fill = valor,
text = text)) +
geom_tile(color = "white") +
scale_fill_gradientn(colours = viridis::viridis(n = 256),
breaks = c(-100, 0, 100, 200, 300, 400, 500, 600, 700, 800),
labels = c(-100, 0, 100, 200, 300, 400, 500, 600, 700, 800)
) +
labs(x = "", y = "",
caption = "Vehículos por cada mil habitantes\nFuente: INEGI. Estadísticas de vehículos de motor registrados en circulación",
title = str_wrap(str_c(coches$variable[1]), 50)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
plot.title = element_text(hjust = 0.5))
plot
# Convertimos a interactivo
plotly::ggplotly(plot, tooltip = "text")
# Treemap
# En caso de que no se tenga d3treeR
# devtools::install_github("timelyportfolio/d3treeR")
library(treemapify)
library(tidyverse)
library(highcharter)
library(treemap)
library(d3treeR)
# Llamamos a la base de Pib para cada país del G20, 2018
data(G20)
G20
# Treemap con ggplot
ggplot(G20, aes(area = gdp_mil_usd,
fill = region,
label = str_c(country, "\n", "$", prettyNum(gdp_mil_usd, big.mark = ",")))) +
geom_treemap() +
geom_treemap_text(colour = "white",
place = "center",
reflow = T,
family = "Arial",
size = 15) +
labs(fill = "Región/Continente",
title = "PIB (Millones de dólares, 2018)") +
scale_fill_manual(values = c(wesanderson::wes_palettes$GrandBudapest1,
wesanderson::wes_palettes$Cavalcanti1)) +
guides(fill=guide_legend(title.position="top",
title.hjust =0.5),
colour=guide_legend(title.position="top",
title.hjust =0.5)) +
theme(legend.position = "bottom",
plot.title = element_text(hjust = 0.5, face = "bold"))
# VER: https://rstudio-pubs-static.s3.amazonaws.com/320413_6ab300527e8548b1a3cbd0d4c6200fcc.html
# VER: https://www.datacamp.com/community/tutorials/data-visualization-highcharter-r
G20 = G20 %>%
mutate(country_2 = str_c(country, ":  $", prettyNum(gdp_mil_usd, big.mark = ",")))
`PIB en Millones de Dólares` <- treemap(G20, index = c("region", "country_2"),
vSize = "gdp_mil_usd", vColor = "region")
d3tree3(`PIB en Millones de Dólares`, celltext = "name")
d3tree3(`PIB en Millones de Dólares`, celltext = "name")
# Opciones
Sys.setlocale("LC_ALL", "es_ES.UTF-8") #mac
# Librerias ----
library(pacman)
p_load(tidyverse,
plotly,
readxl,
scales)
# Base de datos ----
bd <- read_xlsx("01_Datos/TweetsGobernadores.xlsx")
btc <- read_csv("01_Datos/BTC-USD.csv")
# GRÁFICA DE LÍNEAS ----
# Tweets por gobernador
tweets <- bd %>%
group_by(Gobernador, screen_name,
`Fecha de salida`, Partido) %>%
count()
# Formulamos la grafica
plt <- tweets %>%
ggplot(aes(x = reorder(screen_name, n),
fill = Partido,
y = n,
text = paste0("<b>Nombre del gobernador: </b>", Gobernador, "<br>",
"<b>Partido: </b>", Partido, "<br>",
"<b>Fecha de salida: </b>",`Fecha de salida`, "<br>"
))) +
geom_col() +
coord_flip() +
labs(title = "Numero de Tweets emitidos por<br>gobernador la última semana",
x = "",
y = "") +
scale_fill_manual(values = c("pink",
"orange",
"brown",
"blue",
"purple",
"yellow",
"red",
"green"
))
plt
# Convertimos a gráfica interactiva
ggplotly(tooltip = "text")  %>%
config(displayModeBar = F)
# GRÁFICA DE PUNTOS ----
# Cuando twittean los gobernadores
class(bd$created_at)
bd %>%
ggplot(aes(x = created_at,
y = screen_name,
color = Partido,
text = paste0("<b>Emisor: </b>", screen_name, "<br>",
"<b>Texto: </b>", str_wrap(text, 50), "<br>"))) +
geom_point(alpha = 0.3) +
scale_color_manual(values = c("pink",
"orange",
"brown",
"blue",
"purple",
"yellow",
"red",
"green"))
ggplotly(tooltip = "text") %>%
config(displayModeBar = F)
# Gráfica de líneas ----¡-
# Precios de Apertura del BTC a nivel diario
btc <- btc %>%
mutate(Open = as.numeric(Open)) %>%
rename(Fecha = Date,
Apertura = Open,
Cierre = Close)
lin <- btc %>%
ggplot() +
geom_line(aes(x = Fecha,
y = Apertura)) +
theme_bw() +
labs(y = "", x = "")
lin
# WordCloud
library(tidyverse)
library(readxl)
library(wordcloud2)
library(tm)
bd <- read_xlsx("01_Datos/TweetsGobernadores.xlsx")
create_wordcloud <- function(data,
num_words = 100,
background = "white",
stop_words, mask = NULL,
tamanio = 0.5) {
#, palabra = NULL
# Si se provee el texto, convertirlo a un dataframe de frecuencia de palabras
if (is.character(data)) {
# Convertimos a Corpus
corpus <- Corpus(VectorSource(data))
# Convertimos el texto dentro del Corpus a Minusculas
corpus <- tm_map(corpus, tolower)
# Removemos la puntuacion (.,-!?)
corpus <- tm_map(corpus, removePunctuation)
# Removemos los numeros
corpus <- tm_map(corpus, removeNumbers)
# Removemos las stopwords (palabras muy muy comunes que se usan para dar coherencia
# a las oraciones. Para saber cuales, escribir: stopwords("spanish))
corpus <- tm_map(corpus, removeWords, c(stopwords("spanish"), stop_words))
# Generamos una matriz para hacer el conteo
tdm <- as.matrix(TermDocumentMatrix(corpus))
# Obtenemos el numero de la frecuencia de cada palabra
data <- sort(rowSums(tdm), decreasing = TRUE)
# Generamos una tabla con la palabra en una columna y su frecuencia de uso en otra
data <- data.frame(word = names(data), freq = as.numeric(data))
}
# Nos aseguramos que un numero adecuado de palabras `num_provider` es generado`
if (!is.numeric(num_words) || num_words < 3) {
num_words <- 3
}
# Recortamos la base de datos de palabras a un numero `n` especificado
data <- head(data, n = num_words)
if (nrow(data) == 0) {
return(NULL)
}
wordcloud2(data, backgroundColor = background, figPath = mask,  color = "random-light", size = tamanio)
}
# Creamos una wordCloud
create_wordcloud(bd$text, stop_words = c("hola"), num_words = 200)
# WordCloud
library(tidyverse)
library(readxl)
library(wordcloud2)
library(tm)
bd <- read_xlsx("01_Datos/TweetsGobernadores.xlsx")
create_wordcloud <- function(data,
num_words = 100,
background = "white",
stop_words, mask = NULL,
tamanio = 0.5) {
#, palabra = NULL
# Si se provee el texto, convertirlo a un dataframe de frecuencia de palabras
if (is.character(data)) {
# Convertimos a Corpus
corpus <- Corpus(VectorSource(data))
# Convertimos el texto dentro del Corpus a Minusculas
corpus <- tm_map(corpus, tolower)
# Removemos la puntuacion (.,-!?)
corpus <- tm_map(corpus, removePunctuation)
# Removemos los numeros
corpus <- tm_map(corpus, removeNumbers)
# Removemos las stopwords (palabras muy muy comunes que se usan para dar coherencia
# a las oraciones. Para saber cuales, escribir: stopwords("spanish))
corpus <- tm_map(corpus, removeWords, c(stopwords("spanish"), stop_words))
# Generamos una matriz para hacer el conteo
tdm <- as.matrix(TermDocumentMatrix(corpus))
# Obtenemos el numero de la frecuencia de cada palabra
data <- sort(rowSums(tdm), decreasing = TRUE)
# Generamos una tabla con la palabra en una columna y su frecuencia de uso en otra
data <- data.frame(word = names(data), freq = as.numeric(data))
}
# Nos aseguramos que un numero adecuado de palabras `num_provider` es generado`
if (!is.numeric(num_words) || num_words < 3) {
num_words <- 3
}
# Recortamos la base de datos de palabras a un numero `n` especificado
data <- head(data, n = num_words)
if (nrow(data) == 0) {
return(NULL)
}
wordcloud2(data, backgroundColor = background, figPath = mask,  color = "random-light", size = tamanio)
}
# Creamos una wordCloud
create_wordcloud(bd$text, stop_words = c("hola"), num_words = 200)
bd
